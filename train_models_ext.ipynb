{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from typing import Dict, Sequence, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wfdb\n",
    "from torch.nn.parallel import DataParallel as DP\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP  # noqa: F401\n",
    "from torch_ecg.cfg import CFG, DEFAULTS\n",
    "from torch_ecg.utils.misc import str2bool\n",
    "from torch_ecg.utils.utils_nn import default_collate_fn as collate_fn\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from cfg import ModelCfg, TrainCfg\n",
    "from data_reader import CODE15, PTBXL, SamiTrop\n",
    "from dataset import CINC2025Dataset\n",
    "from models import CRNN_CINC2025, FM_CINC2025\n",
    "from outputs import CINC2025Outputs\n",
    "from trainer import CINC2025Trainer\n",
    "from utils.samplers import BalancedBatchSampler\n",
    "\n",
    "# sys.path.insert(0, \"/home/wenh06/Jupyter/wenhao/workspace/torch_ecg/\")\n",
    "# sys.path.insert(0, \"/home/wenh06/Jupyter/wenhao/workspace/bib_lookup/\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = Path(\"/home/wenh06/Jupyter/Hot-data/cinc2025/\")\n",
    "# db_dir = Path(\"/home/wenh06/Jupyter/Hot-data/cinc2025-test/\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FLAG = False\n",
    "\n",
    "if ModelCfg.torch_dtype == torch.float64:\n",
    "    torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "    DTYPE = np.float64\n",
    "else:\n",
    "    DTYPE = np.float32\n",
    "\n",
    "CINC2025Dataset.__DEBUG__ = False\n",
    "CRNN_CINC2025.__DEBUG__ = False\n",
    "FM_CINC2025.__DEBUG__ = False\n",
    "CINC2025Trainer.__DEBUG__ = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeats = 4\n",
    "# for subsample in [0.01, 0.1, 0.5, 1.0]:\n",
    "for subsample in [0.01]:\n",
    "    for _ in range(repeats):\n",
    "        train_config = deepcopy(TrainCfg)\n",
    "        train_config.db_dir = db_dir\n",
    "        train_config.debug = True\n",
    "\n",
    "        train_config.n_epochs = 20\n",
    "        train_config.batch_size = 192  # 16G (Tesla T4)\n",
    "        # train_config.log_step = 20\n",
    "\n",
    "        # for CRNN only, comment if using FM_CINC2025\n",
    "        train_config.learning_rate = 3e-4  # 5e-4, 1e-3\n",
    "        train_config.lr = train_config.learning_rate\n",
    "        train_config.max_lr = 9e-4\n",
    "\n",
    "        train_config.keep_checkpoint_max = 0\n",
    "\n",
    "        train_config.lr_scheduler = \"one_cycle\"\n",
    "        train_config.early_stopping.patience = train_config.n_epochs // 3\n",
    "\n",
    "        train_config.extra_experiment = True\n",
    "        train_config.subsample = subsample  # 0.01, 0.10, 0.5, 1.0\n",
    "\n",
    "        # augmentations configurations\n",
    "        # TODO: add augmentation configs\n",
    "\n",
    "        model_config = deepcopy(ModelCfg)\n",
    "        # model_config\n",
    "\n",
    "        model_config.crnn.dem_encoder.mode = \"film\"\n",
    "        model = CRNN_CINC2025(config=model_config.crnn)\n",
    "        # model_config.fm.backbone_cache_dir = \"/home/wenh06/Jupyter/models/ST-MEM/st_mem_vit_base_encoder.pth\"\n",
    "        # model = FM_CINC2025(config=model_config.fm)\n",
    "\n",
    "        model = model.to(device=DEVICE)\n",
    "        if isinstance(model, DP):\n",
    "            print(\"model size:\", model.module.module_size, model.module.module_size_)\n",
    "            print(\"Using devices:\", model.device_ids)\n",
    "        else:\n",
    "            print(\"model size:\", model.module_size, model.module_size_)\n",
    "            print(\"Using device:\", model.device)\n",
    "\n",
    "        ds_train = CINC2025Dataset(train_config, training=True, lazy=True)\n",
    "        ds_val = CINC2025Dataset(train_config, training=False, lazy=True)\n",
    "\n",
    "        if isinstance(model, FM_CINC2025):\n",
    "            print(\"Using FM_CINC2025 model, adjusting fs and input_len\")\n",
    "            ds_train.reset_resample_fs(model_config.fm.fs[model_config.fm.name], reload=False)\n",
    "            ds_train.reset_input_len(model_config.fm.input_len[model_config.fm.name], reload=False)\n",
    "            ds_val.reset_resample_fs(model_config.fm.fs[model_config.fm.name], reload=False)\n",
    "            ds_val.reset_input_len(model_config.fm.input_len[model_config.fm.name], reload=False)\n",
    "\n",
    "        trainer = CINC2025Trainer(\n",
    "            model=model,\n",
    "            model_config=model_config,\n",
    "            train_config=train_config,\n",
    "            device=DEVICE,\n",
    "            lazy=True,\n",
    "        )\n",
    "        trainer._setup_dataloaders(ds_train, ds_val)\n",
    "        best_model_state_dict = trainer.train()\n",
    "\n",
    "        trainer.log_manager.flush()\n",
    "        trainer.log_manager.close()\n",
    "\n",
    "        del trainer, model, best_model_state_dict, ds_train, ds_val\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Results analyze and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[\"resnet-nc\"] = pd.read_csv(\n",
    "    \"./results/TorchECG_02-21_17-38_CRNN_CINC2025_resnet_nature_comm_bottle_neck_adamw_amsgrad_LR_0.0001_BS_128.csv\"\n",
    ")\n",
    "df_results[\"resnet-nc-se\"] = pd.read_csv(\n",
    "    \"./results/TorchECG_02-22_01-33_CRNN_CINC2025_resnet_nature_comm_bottle_neck_se_adamw_amsgrad_LR_0.0001_BS_128.csv\"\n",
    ")\n",
    "df_results[\"tresnet-m\"] = pd.read_csv(\n",
    "    \"./results/TorchECG_02-22_09-09_CRNN_CINC2025_tresnetM_adamw_amsgrad_LR_0.0001_BS_128.csv\"\n",
    ")\n",
    "df_results[\"tresnet-n\"] = pd.read_csv(\n",
    "    \"./results/TorchECG_02-22_01-38_CRNN_CINC2025_tresnetN_adamw_amsgrad_LR_0.0001_BS_128.csv\"\n",
    ")\n",
    "df_results[\"tresnet-f\"] = pd.read_csv(\n",
    "    \"./results/TorchECG_02-22_09-13_CRNN_CINC2025_tresnetF_adamw_amsgrad_LR_0.0001_BS_128.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "part = \"train\"\n",
    "metric = \"challenge_score\"\n",
    "\n",
    "for k, df in df_results.items():\n",
    "    df_metric = df[df.part == part][[metric, \"epoch\"]].dropna()\n",
    "    ax.plot(df_metric.epoch, df_metric[metric], label=k)\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "part = \"val\"\n",
    "metric = \"challenge_score\"\n",
    "\n",
    "for k, df in df_results.items():\n",
    "    df_metric = df[df.part == part][[metric, \"epoch\"]].dropna()\n",
    "    ax.plot(df_metric.epoch, df_metric[metric], label=k)\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "part = \"train\"\n",
    "metric = \"chagas_f_measure\"\n",
    "\n",
    "for k, df in df_results.items():\n",
    "    df_metric = df[df.part == part][[metric, \"epoch\"]].dropna()\n",
    "    ax.plot(df_metric.epoch, df_metric[metric], label=k)\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "part = \"val\"\n",
    "metric = \"chagas_f_measure\"\n",
    "\n",
    "for k, df in df_results.items():\n",
    "    df_metric = df[df.part == part][[metric, \"epoch\"]].dropna()\n",
    "    ax.plot(df_metric.epoch, df_metric[metric], label=k)\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
